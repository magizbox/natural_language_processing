{
    "docs": [
        {
            "location": "/", 
            "text": "Natural Language Processing\n\n\n\n\nNatural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.\n\n\nNLP is related to the area of human\u2013computer interaction. Many challenges in NLP involve: natural language understanding, enabling computers to derive meaning from human or natural language input; and others involve natural language generation.\n\n\nThe input and output of an NLP system can be either speech or written text.\n\n\n\n\nComponents of NLP\n\n\nThere are two components of NLP as given\n\n\n\n\nNatural Language Understanding (NLU)\n: this task mapping the given input in natural language into useful representations and analyzing different aspects of the language.\n\n\nNatural Language Generation (NLG)\n: In the process of producing meaningful phrases and sentences in the form of natural language form some internal representation. It involves \ntext planning\n retrieve the relevant content from knowledge base, \nsentence planning\n choose required words, forming meaningful phrases, setting tone of the sentence, \ntext realization\n map sentence plan into sentence structure.\n\n\n\n\nDifficulties\n\n\nNatural Language has an extremely rich form and structure. It is very ambiguous. There can be different levels of ambiguity\n\n\n\n\nLexical ambiguity\n: it is at very primitive level such as word-level. For example, treating the word \"board\" as noun or verb?\n\n\nSyntax level ambiguity\n: A sentence be parsed in different ways. For example, \"He lifted the beetle with the red cap?\" - did he use cap to lift the beetle or he lifted a beetle that had red cap?\n\n\nReferential ambiguity\n: referring to something using pronouns. For example, Rima went to Gauri. She said \"I am tired\". - Exactly who is tired?\n\n\nOne input can mean different meanings.\n\n\nMany inputs can mean the same thing.\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\nCourses", 
            "title": "Home"
        }, 
        {
            "location": "/#natural-language-processing", 
            "text": "Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.  NLP is related to the area of human\u2013computer interaction. Many challenges in NLP involve: natural language understanding, enabling computers to derive meaning from human or natural language input; and others involve natural language generation.  The input and output of an NLP system can be either speech or written text.   Components of NLP  There are two components of NLP as given   Natural Language Understanding (NLU) : this task mapping the given input in natural language into useful representations and analyzing different aspects of the language.  Natural Language Generation (NLG) : In the process of producing meaningful phrases and sentences in the form of natural language form some internal representation. It involves  text planning  retrieve the relevant content from knowledge base,  sentence planning  choose required words, forming meaningful phrases, setting tone of the sentence,  text realization  map sentence plan into sentence structure.   Difficulties  Natural Language has an extremely rich form and structure. It is very ambiguous. There can be different levels of ambiguity   Lexical ambiguity : it is at very primitive level such as word-level. For example, treating the word \"board\" as noun or verb?  Syntax level ambiguity : A sentence be parsed in different ways. For example, \"He lifted the beetle with the red cap?\" - did he use cap to lift the beetle or he lifted a beetle that had red cap?  Referential ambiguity : referring to something using pronouns. For example, Rima went to Gauri. She said \"I am tired\". - Exactly who is tired?  One input can mean different meanings.  Many inputs can mean the same thing.", 
            "title": "Natural Language Processing"
        }, 
        {
            "location": "/#books", 
            "text": "", 
            "title": "Books"
        }, 
        {
            "location": "/#courses", 
            "text": "", 
            "title": "Courses"
        }, 
        {
            "location": "/task/", 
            "text": "NLP Tasks\n\n\nThe analysis of natural language is broken into various board levels such as phonological, morphological, syntactic, semantic, pragmatic and discourse analysis.\n\n\n\n\nPhonological Analysis\n\n\nPhonology is analysis of spoken language. Therefore, it deals with speech recognition and generation. The core task of speech recognition and generation system is to take an acoustic waveform as input and produce as output, a string of words. The phonology is a part of natural language analysis, which deals with it. The area of computational linguistics that deals with speech analysis is computational phonology\n\n\nExample:\n \nHans Rosling's shortest TED talk\n\n\n\n\n\n\n\nOriginal Sound\n\n\n\n\n\n  \n\nYour browser does not support the audio element.\n\n\n\n\n\n\n\n\n\nText\n\n\n\nX means unknown but the world is pretty known it's seven billion people have seven stones. One billion can save money to fly abroad on holiday every year. One billion can save money to keep a car or buy a car. And then three billion they save money to pay the by be a bicycle or perhaps a two-wheeler. And two billion they are busy saving money to buy shoes. In the future they will get rich and these people we move over here, these people will move over here, we will have two billion more in the world like this and the question is whether the rich people over there are prepared to be integrated in the world with 10 bilions people.\n\n\n\n\n\n\n\nAuto generated sound\n\n\n\n\n\n  \n\nYour browser does not support the audio element.\n\n\n\n\n\n\n\n\n\n\nMorphological Analysis\n\n\nIt is the most elementary phase of NLP. It deals with the word formation. In this phase, individual words are analyzed according to their components called \n\"morphemes\"\n. In addition, non-word taken such as punctuation, etc. are separated from words. Morpheme is basic grammatical building block that makes words.\n\n\n\n\nThe study of word structure is refereed to as morphology. In natural language processing, it is done in morphological analysis. The task of breaking a word into its morphemes is called morphological parsing. A morpheme is defined as minimal meaningful unit in a language, which cannot be further broken into smaller units.\n\n\nExample: word \nfox\n consists a single morpheme, as it cannot be further resolved into smaller units. Whereas word \ncats\n consists two morphemes, the morpheme \"cat\" and morpheme \"s\" indicating plurality.\n\n\nHere we defined the term meaningful. Though cat can be broken in \"c\" and \"at\", but these do not relate with word \"cat\" in any sense. Thus word \"cat\" will be dealt with as minimum meaningful unit.\n\n\nMorphemes are traditionally divided into two types\n\n\n\n\n(i) \"free morphemes\", that are able to act as words in isolation (e.g., \"thing\", \"permanent\", \"local\")\n\n\n(ii) \"bound morphemes\", that can operate only as part of other words (e.g., \"is\" 'ing' etc) The morpheme, which forms the center part of the world, is also called \"stem\". In English, a word can be made up of one or more morphemes, e.g.,\n\n\n\n\nword - thing           -\n stem \nthink\n\nword - localize        -\n stem \nlocal\n, suffix \nize\n\nword - denationalize   -\n prefix \nde\n, stem \nnation\n, suffix \nal\n, \nize\n\n\n\n\n\nThe computational tool to perform morphological parsing is finite state transducer. A transducer performs it by mapping between the two sets of symbols, and a finite state transducer does it with finite automaton. A transducer normally consists of four parts: \nrecognizer\n, \ngenerator\n,  \ntranslator\n, and \nrelator\n. The output of the transducer becomes a set of morphemes.\n\n\nLexical Analysis\n\n\nIn this phase of natural language analysis, validity of words according to lexicon is checked. Lexicon stands for dictionary. It is a collection of all possible valid words of language along with their meaning.\n\n\nIn NLP, the first stage of processing input text is to scan each word in sentence and compute (or look-up) all the relevant linguistic information about that word. The lexicon provides the necessary rules and data for carrying out the first stage analysis.\n\n\nThe details of words, like their type (noun, verb and adverb, and other details of nouns and verb, etc.) are checked.\n\n\n\n\nLexical analysis is dividing the whole chunk of text into paragraphs, sentences, and words.\n\n\nSyntactic Analysis\n\n\nSyntax refers to the study of formal relationships between words of sentences. In this phase the validity of a sentence according to grammar rules is checked. To perform the syntactic analysis, the knowledge of grammar and parsing is required. Grammar is formal specification of rules allowable in the language, and parsing is a method of analyzing a sentence to determine its structure according to grammar. The most common grammar used for syntactic analysis for natural languages are \ncontext free grammar\n (CFG) also called \nphase structure grammar\n and \ndefinite clause grammar\n. These grammars are described in detail in a separate actions.\n\n\n\n\nSyntactic analysis is done using parsing. Two basic parsing techniques are: \ntop-down parsing\n and \nbottom-up parsing\n.\n\n\nSemantic Analysis\n\n\nIn linguistics, semantic analysis is the process of relating syntactic structures, from the levels of phrases, clauses, sentences and paragraphs to the level of the writing as a whole, to their language-independent meanings. It also involves removing features specific to particular linguistic and cultural contexts, to the extent that such a project is possible.\n\n\nThe elements of idiom and figurative speech, being cultural, are often also converted into relatively invariant meanings in semantic analysis. Semantics, although related to pragmatics, is distinct in that the former deals with word or sentence choice in any given context, while pragmatics considers the unique or particular meaning derived from context or tone. To reiterate in different terms, semantics is about universally coded meaning, and pragmatics the meaning encoded in words that is then interpreted by an audience\n\n\nDiscourse Analysis\n\n\nThe meaning of any sentence depends upon the meaning of the sentence just before it. In addition, it also brings about the meaning of immediately succeeding sentence.\n\n\nTopics of discourse analysis include:\n\n\n\n\nThe various levels or dimensions of discourse, such as sounds, gestures, syntrax, the lexicon, style, rhetoric, meanings, speech acts, moves, strategies, turns, and other aspects of interaction\n\n\nGenres of discourse (various types of discourse in politics, the media, education, science, business, etc.)\n\n\nThe relations between text (discourse) and context\n\n\nThe relations between discourse and power\n\n\nThe relations between discourse and interaction\n\n\nThe relations between discourse and cognition and memory\n\n\n\n\nPragmatic Analysis\n\n\nDuring this, what was said is re-interpreted on what it actually meant. It involves deriving those aspects of language which require real world knowledge.\n\n\nSentiment Analysis\n\n\nMetaMind\n,\u00a0@RichardSocher\n\n\nNamed Entity Recognition\n\n\nKDD 2015 Tutorial: Automatic Entity Recognition and Typing from Massive Text Corpora - A Phrase and Network Mining Approach\n\n\nRelationship Extraction\n\n\nAlchemyAPI\n\n\nReferences\n\n\n\n\nKumar, Ela. \nNatural Language Processing\n. New Delhi: I.K. International Publishing House, 2011\n\n\n\"Artificial Intelligence Natural Language Processing\".\u00a0\nwww.tutorialspoint.com\n. N.p., 2016. Web. 11 Oct. 2016.", 
            "title": "Tasks"
        }, 
        {
            "location": "/task/#nlp-tasks", 
            "text": "The analysis of natural language is broken into various board levels such as phonological, morphological, syntactic, semantic, pragmatic and discourse analysis.", 
            "title": "NLP Tasks"
        }, 
        {
            "location": "/task/#phonological-analysis", 
            "text": "Phonology is analysis of spoken language. Therefore, it deals with speech recognition and generation. The core task of speech recognition and generation system is to take an acoustic waveform as input and produce as output, a string of words. The phonology is a part of natural language analysis, which deals with it. The area of computational linguistics that deals with speech analysis is computational phonology  Example:   Hans Rosling's shortest TED talk    Original Sound   \n   \nYour browser does not support the audio element.     Text  \nX means unknown but the world is pretty known it's seven billion people have seven stones. One billion can save money to fly abroad on holiday every year. One billion can save money to keep a car or buy a car. And then three billion they save money to pay the by be a bicycle or perhaps a two-wheeler. And two billion they are busy saving money to buy shoes. In the future they will get rich and these people we move over here, these people will move over here, we will have two billion more in the world like this and the question is whether the rich people over there are prepared to be integrated in the world with 10 bilions people.    Auto generated sound   \n   \nYour browser does not support the audio element.", 
            "title": "Phonological Analysis"
        }, 
        {
            "location": "/task/#morphological-analysis", 
            "text": "It is the most elementary phase of NLP. It deals with the word formation. In this phase, individual words are analyzed according to their components called  \"morphemes\" . In addition, non-word taken such as punctuation, etc. are separated from words. Morpheme is basic grammatical building block that makes words.   The study of word structure is refereed to as morphology. In natural language processing, it is done in morphological analysis. The task of breaking a word into its morphemes is called morphological parsing. A morpheme is defined as minimal meaningful unit in a language, which cannot be further broken into smaller units.  Example: word  fox  consists a single morpheme, as it cannot be further resolved into smaller units. Whereas word  cats  consists two morphemes, the morpheme \"cat\" and morpheme \"s\" indicating plurality.  Here we defined the term meaningful. Though cat can be broken in \"c\" and \"at\", but these do not relate with word \"cat\" in any sense. Thus word \"cat\" will be dealt with as minimum meaningful unit.  Morphemes are traditionally divided into two types   (i) \"free morphemes\", that are able to act as words in isolation (e.g., \"thing\", \"permanent\", \"local\")  (ii) \"bound morphemes\", that can operate only as part of other words (e.g., \"is\" 'ing' etc) The morpheme, which forms the center part of the world, is also called \"stem\". In English, a word can be made up of one or more morphemes, e.g.,   word - thing           -  stem  think \nword - localize        -  stem  local , suffix  ize \nword - denationalize   -  prefix  de , stem  nation , suffix  al ,  ize   The computational tool to perform morphological parsing is finite state transducer. A transducer performs it by mapping between the two sets of symbols, and a finite state transducer does it with finite automaton. A transducer normally consists of four parts:  recognizer ,  generator ,   translator , and  relator . The output of the transducer becomes a set of morphemes.", 
            "title": "Morphological Analysis"
        }, 
        {
            "location": "/task/#lexical-analysis", 
            "text": "In this phase of natural language analysis, validity of words according to lexicon is checked. Lexicon stands for dictionary. It is a collection of all possible valid words of language along with their meaning.  In NLP, the first stage of processing input text is to scan each word in sentence and compute (or look-up) all the relevant linguistic information about that word. The lexicon provides the necessary rules and data for carrying out the first stage analysis.  The details of words, like their type (noun, verb and adverb, and other details of nouns and verb, etc.) are checked.   Lexical analysis is dividing the whole chunk of text into paragraphs, sentences, and words.", 
            "title": "Lexical Analysis"
        }, 
        {
            "location": "/task/#syntactic-analysis", 
            "text": "Syntax refers to the study of formal relationships between words of sentences. In this phase the validity of a sentence according to grammar rules is checked. To perform the syntactic analysis, the knowledge of grammar and parsing is required. Grammar is formal specification of rules allowable in the language, and parsing is a method of analyzing a sentence to determine its structure according to grammar. The most common grammar used for syntactic analysis for natural languages are  context free grammar  (CFG) also called  phase structure grammar  and  definite clause grammar . These grammars are described in detail in a separate actions.   Syntactic analysis is done using parsing. Two basic parsing techniques are:  top-down parsing  and  bottom-up parsing .", 
            "title": "Syntactic Analysis"
        }, 
        {
            "location": "/task/#semantic-analysis", 
            "text": "In linguistics, semantic analysis is the process of relating syntactic structures, from the levels of phrases, clauses, sentences and paragraphs to the level of the writing as a whole, to their language-independent meanings. It also involves removing features specific to particular linguistic and cultural contexts, to the extent that such a project is possible.  The elements of idiom and figurative speech, being cultural, are often also converted into relatively invariant meanings in semantic analysis. Semantics, although related to pragmatics, is distinct in that the former deals with word or sentence choice in any given context, while pragmatics considers the unique or particular meaning derived from context or tone. To reiterate in different terms, semantics is about universally coded meaning, and pragmatics the meaning encoded in words that is then interpreted by an audience", 
            "title": "Semantic Analysis"
        }, 
        {
            "location": "/task/#discourse-analysis", 
            "text": "The meaning of any sentence depends upon the meaning of the sentence just before it. In addition, it also brings about the meaning of immediately succeeding sentence.  Topics of discourse analysis include:   The various levels or dimensions of discourse, such as sounds, gestures, syntrax, the lexicon, style, rhetoric, meanings, speech acts, moves, strategies, turns, and other aspects of interaction  Genres of discourse (various types of discourse in politics, the media, education, science, business, etc.)  The relations between text (discourse) and context  The relations between discourse and power  The relations between discourse and interaction  The relations between discourse and cognition and memory", 
            "title": "Discourse Analysis"
        }, 
        {
            "location": "/task/#pragmatic-analysis", 
            "text": "During this, what was said is re-interpreted on what it actually meant. It involves deriving those aspects of language which require real world knowledge.", 
            "title": "Pragmatic Analysis"
        }, 
        {
            "location": "/task/#sentiment-analysis", 
            "text": "MetaMind ,\u00a0@RichardSocher", 
            "title": "Sentiment Analysis"
        }, 
        {
            "location": "/task/#named-entity-recognition", 
            "text": "KDD 2015 Tutorial: Automatic Entity Recognition and Typing from Massive Text Corpora - A Phrase and Network Mining Approach", 
            "title": "Named Entity Recognition"
        }, 
        {
            "location": "/task/#relationship-extraction", 
            "text": "AlchemyAPI", 
            "title": "Relationship Extraction"
        }, 
        {
            "location": "/task/#references", 
            "text": "Kumar, Ela.  Natural Language Processing . New Delhi: I.K. International Publishing House, 2011  \"Artificial Intelligence Natural Language Processing\".\u00a0 www.tutorialspoint.com . N.p., 2016. Web. 11 Oct. 2016.", 
            "title": "References"
        }, 
        {
            "location": "/spelling_correction/", 
            "text": "Spelling Correction\n\n\nFor instance, we may wish to retrieve documents containing the term carrot when the user types the query carot. Google reports (http://www.google.com/jobs/britney.html) that the following are all treated as misspellings of the query britney spears: britian spears, britney's spears, brandy spears and prittany spears\n\n\nWe look at two steps to solving this problem: the first based on \nedit distance\n and the second based on \nk-gram overlap\n. Before getting into the algorithmic details of these methods, we first review how search engines provide spell-correction as part of a user experience.\n\n\nImplementing spelling correction\n\n\nThere are two basic principles underlying most spelling correction algorithms.\n\n\n\n\nOf various alternative correct spellings for a mis-spelled query, choose the \nnearest\n one. This demands that we have a notion of nearness or proximity between a pair of queries. \n\n\nWhen two correctly spelled queries are tied (or nearly tied), select the one that is \nmore common\n. For instance, grunt and grant both seem equally plausible as corrections for grnt. Then, the algorithm should choose the more common of grunt and grant as the correction. The simplest notion of more common is to consider the number of occurrences of the term in the collection; thus if grunt occurs more often than grant, it would be the chosen correction. A different notion of more common is employed in many search engines, especially on the web. The idea is to use the correction that is most common among queries typed in by other users. The idea here is that if grunt is typed as a query more often than grant, then it is more likely that the user who typed grnt intended to type the query grunt.\n\n\n\n\nCorpus\n\n\nBirkbeck spelling error corpus\n\n\nReferences\n\n\n\n\nHow to Write a Spelling Corrector. \nPeter Norvig\n. 2007\n\n\nStatistical Natural Language Processing in Python. \nPeter Norvig\n. 2007\n\n\nSpelling correction. \nIntroduction to Information Retrieval\n. 2008", 
            "title": "Spelling Correction"
        }, 
        {
            "location": "/spelling_correction/#spelling-correction", 
            "text": "For instance, we may wish to retrieve documents containing the term carrot when the user types the query carot. Google reports (http://www.google.com/jobs/britney.html) that the following are all treated as misspellings of the query britney spears: britian spears, britney's spears, brandy spears and prittany spears  We look at two steps to solving this problem: the first based on  edit distance  and the second based on  k-gram overlap . Before getting into the algorithmic details of these methods, we first review how search engines provide spell-correction as part of a user experience.", 
            "title": "Spelling Correction"
        }, 
        {
            "location": "/spelling_correction/#implementing-spelling-correction", 
            "text": "There are two basic principles underlying most spelling correction algorithms.   Of various alternative correct spellings for a mis-spelled query, choose the  nearest  one. This demands that we have a notion of nearness or proximity between a pair of queries.   When two correctly spelled queries are tied (or nearly tied), select the one that is  more common . For instance, grunt and grant both seem equally plausible as corrections for grnt. Then, the algorithm should choose the more common of grunt and grant as the correction. The simplest notion of more common is to consider the number of occurrences of the term in the collection; thus if grunt occurs more often than grant, it would be the chosen correction. A different notion of more common is employed in many search engines, especially on the web. The idea is to use the correction that is most common among queries typed in by other users. The idea here is that if grunt is typed as a query more often than grant, then it is more likely that the user who typed grnt intended to type the query grunt.", 
            "title": "Implementing spelling correction"
        }, 
        {
            "location": "/spelling_correction/#corpus", 
            "text": "Birkbeck spelling error corpus", 
            "title": "Corpus"
        }, 
        {
            "location": "/spelling_correction/#references", 
            "text": "How to Write a Spelling Corrector.  Peter Norvig . 2007  Statistical Natural Language Processing in Python.  Peter Norvig . 2007  Spelling correction.  Introduction to Information Retrieval . 2008", 
            "title": "References"
        }, 
        {
            "location": "/word_vectors/", 
            "text": "Discrete Representation\n\n\nUse a taxonomy like WordNet that has hypernyms (is-a) relationships\n\n\nfrom nltk.corpus import wordnet as wn\npanda = wn.synset(\npanda.n.01\n)\nhyper = lambda s: s.hypernyms()\nlist(panda.closure(hyper))\n\n\n\n\n[Synset('procyonid.n.01'),\n Synset('carnivore.n.01'),\n Synset('placental.n.01'),\n Synset('mammal.n.01'),\n Synset('vertebrate.n.01'),\n Synset('chordate.n.01'),\n Synset('animal.n.01'),\n Synset('organism.n.01'),\n Synset('living_thing.n.01'),\n Synset('whole.n.02'),\n Synset('object.n.01'),\n Synset('physical_entity.n.01'),\n Synset('entity.n.01')]\n\n\n\n\nwn.synsets(\ngood\n)\n\n\n\n\n[Synset('good.n.01'),\n Synset('good.n.02'),\n Synset('good.n.03'),\n Synset('commodity.n.01'),\n Synset('good.a.01'),\n Synset('full.s.06'),\n Synset('good.a.03'),\n Synset('estimable.s.02'),\n Synset('beneficial.s.01'),\n ...\n\n\n\n\nwn.synsets(\nbad\n)\n\n\n\n\n[Synset('bad.n.01'),\n Synset('bad.a.01'),\n Synset('bad.s.02'),\n Synset('bad.s.03'),\n Synset('bad.s.04'),\n Synset('regretful.a.01'),\n Synset('bad.s.06'),\n Synset('bad.s.07'),\n Synset('bad.s.08'),\n ...\n\n\n\n\nProblems with this discrete representation\n\n\n\n\nGreat as resource but missing nuances, e.g. \nsynonyms\n: adept, expert, good, practiced, proficient, skillful?\n\n\nMissing new words (impossible to keep up to date): wicked, badass, nifty, crack, ace, wizard, genius, ninjia\n\n\nSubjective\n\n\nRequires human labor to create and adapt\n\n\nHard to compute accurate word similarity\n\n\n\n\nWord2Vec\n\n\nWord2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n\n\nWord2vec was created by a team of researchers led by Tomas Mikolov at Google. The algorithm has been subsequently analysed and explained by other researchers. Embedding vectors created using the Word2vec algorithm have many advantages compared to earlier algorithms like Latent Semantic Analysis.\n\n\nMain Idea of Word2Vec\n\n\n\n\nInstead of capturing cooccurrence counts directly,,\n\n\nPredict surrounding words of every word\n\n\nBoth are quite similar, see \"Glove: Global Vectors for Word Representation\" by Pennington et at. (2014) and Levy and Goldberg (2014)... more later.\n\n\nFaster and can easily incorporate a new sentence/document or add a word to the vocabulary.\n\n\n\n\nDetail of Word2Vec\n\n\n\n\nPredict surrounding words in a window of length m of every word.\n\n\nObjective function: Maximize the log probability of any context word given the current cenetr word:\n\n\n\n\n\n\nJ(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\le j \\le m, j \\ne 0} log\\ p(w_{t+j}|w_t) \n\n\n\n\nwhere \n \\theta \n represents all variables we optimize\n\n\n\n\nPredict surrounding words in a window of length m of every word\n\n\nFor \n p(w_{t+j}|w_t) \n the simplest first formulation is\n\n\n\n\n\n\np(o|c) = \\frac{exp(u^T_o v_c)}{\\sum_{w=1}^{W} exp(u^T_w v_c)}\n\n\n\n\nwhere o is the outside (or output) word id, c is the center word id, u and v are \"center\" and \"outside\" vectors of o and c\n\n\n\n\nEvery word has two vectors!\n\n\nThis is essentially \"dynamic\" logistic regression\n\n\n\n\nLinear Relationships in word2vec\n\n\nThese representations are \nvery good\n at encoding dimensions of similarity!\n\n\n\n\nAnalogies testing dimensions of similarity can be solved quite well just by doing vector subtraction in the embedding space\n\n\n\n\nSyntactically\n\n\n\n\n\n\n x_{apple} - x_{apples} \\approx x_{car} - x_{cars} \\approx x_{family} - x_{families} \n\n\n\n\nSimilarly for verb and adjective morphological forms\n\n\n\n\nSemantically (Semeval 2012 task 2)\n\n\n\n\n\n\n x_{shirt} - x_{clothing} \\approx x_{chair} - x_{furniture} \n\n\n\n\n\n\n x_{king} - x_{man} \\approx x_{queen} - x_{woman} \n\n\n\n\n\n\nSuggested Readings\n\n\n\n\nSimple Word Vector representations: word2vec, GloVe\n\n\nDistributed Representations of Words and Phrases\nand their Compositionality\n\n\nEfficient Estimation of Word Representations in Vector Space", 
            "title": "Word Vectors"
        }, 
        {
            "location": "/word_vectors/#discrete-representation", 
            "text": "Use a taxonomy like WordNet that has hypernyms (is-a) relationships  from nltk.corpus import wordnet as wn\npanda = wn.synset( panda.n.01 )\nhyper = lambda s: s.hypernyms()\nlist(panda.closure(hyper))  [Synset('procyonid.n.01'),\n Synset('carnivore.n.01'),\n Synset('placental.n.01'),\n Synset('mammal.n.01'),\n Synset('vertebrate.n.01'),\n Synset('chordate.n.01'),\n Synset('animal.n.01'),\n Synset('organism.n.01'),\n Synset('living_thing.n.01'),\n Synset('whole.n.02'),\n Synset('object.n.01'),\n Synset('physical_entity.n.01'),\n Synset('entity.n.01')]  wn.synsets( good )  [Synset('good.n.01'),\n Synset('good.n.02'),\n Synset('good.n.03'),\n Synset('commodity.n.01'),\n Synset('good.a.01'),\n Synset('full.s.06'),\n Synset('good.a.03'),\n Synset('estimable.s.02'),\n Synset('beneficial.s.01'),\n ...  wn.synsets( bad )  [Synset('bad.n.01'),\n Synset('bad.a.01'),\n Synset('bad.s.02'),\n Synset('bad.s.03'),\n Synset('bad.s.04'),\n Synset('regretful.a.01'),\n Synset('bad.s.06'),\n Synset('bad.s.07'),\n Synset('bad.s.08'),\n ...  Problems with this discrete representation   Great as resource but missing nuances, e.g.  synonyms : adept, expert, good, practiced, proficient, skillful?  Missing new words (impossible to keep up to date): wicked, badass, nifty, crack, ace, wizard, genius, ninjia  Subjective  Requires human labor to create and adapt  Hard to compute accurate word similarity", 
            "title": "Discrete Representation"
        }, 
        {
            "location": "/word_vectors/#word2vec", 
            "text": "Word2vec is a group of related models that are used to produce word embeddings. These models are shallow, two-layer neural networks that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large corpus of text and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.  Word2vec was created by a team of researchers led by Tomas Mikolov at Google. The algorithm has been subsequently analysed and explained by other researchers. Embedding vectors created using the Word2vec algorithm have many advantages compared to earlier algorithms like Latent Semantic Analysis.  Main Idea of Word2Vec   Instead of capturing cooccurrence counts directly,,  Predict surrounding words of every word  Both are quite similar, see \"Glove: Global Vectors for Word Representation\" by Pennington et at. (2014) and Levy and Goldberg (2014)... more later.  Faster and can easily incorporate a new sentence/document or add a word to the vocabulary.   Detail of Word2Vec   Predict surrounding words in a window of length m of every word.  Objective function: Maximize the log probability of any context word given the current cenetr word:    J(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\le j \\le m, j \\ne 0} log\\ p(w_{t+j}|w_t)    where   \\theta   represents all variables we optimize   Predict surrounding words in a window of length m of every word  For   p(w_{t+j}|w_t)   the simplest first formulation is    p(o|c) = \\frac{exp(u^T_o v_c)}{\\sum_{w=1}^{W} exp(u^T_w v_c)}   where o is the outside (or output) word id, c is the center word id, u and v are \"center\" and \"outside\" vectors of o and c   Every word has two vectors!  This is essentially \"dynamic\" logistic regression   Linear Relationships in word2vec  These representations are  very good  at encoding dimensions of similarity!   Analogies testing dimensions of similarity can be solved quite well just by doing vector subtraction in the embedding space   Syntactically     x_{apple} - x_{apples} \\approx x_{car} - x_{cars} \\approx x_{family} - x_{families}    Similarly for verb and adjective morphological forms   Semantically (Semeval 2012 task 2)     x_{shirt} - x_{clothing} \\approx x_{chair} - x_{furniture}      x_{king} - x_{man} \\approx x_{queen} - x_{woman}", 
            "title": "Word2Vec"
        }, 
        {
            "location": "/word_vectors/#suggested-readings", 
            "text": "Simple Word Vector representations: word2vec, GloVe  Distributed Representations of Words and Phrases\nand their Compositionality  Efficient Estimation of Word Representations in Vector Space", 
            "title": "Suggested Readings"
        }, 
        {
            "location": "/ner_crf/", 
            "text": "Conditional Random Fields in Name Entity Recognition\n\n\nIn this tutorial, I will write about how to using CRF++ to train your data for name entity recognition task.\n\n\nEnvironment:\n\n\n\n\nUbuntu 14.04\n\n\n\n\nInstall CRF++\n\n\n\n\n\n\nDownload CRF++-0.58.tar.gz\n\n\n\n\n\n\nExtact CRF++-0.58.tar.gz file\n\n\n\n\n\n\nNavigate to the location of extracted folder through\n\n\n\n\n\n\nInstall CRF++ from source\n\n\n\n\n\n\n./configure\nmake\nsudo make install\nldconfig\n\n\n\n\nCongratulations! CRF++ is install\n\n\ncrf_learn\n\n\n\n\nTraining CRF\n\n\nTo train a CRF using CRF++, you need 2 things:\n\n\n\n\nA template file: where you define features to be considered for training\n\n\nA training data file: where you have data in CoNLL format\n\n\n\n\ncrf_learn -t template_file train_data_file model\n\ncrf_learn -t template train.txt model\n\n\n\n\nA binary of model is produce.\n\n\nTo test this model, on a testing data\n\n\ncrf_test -m model testfile \n output.txt\n\ncrf_test -m model test.txt \n output.txt\n\n\n\n\nReferences\n\n\n\n\nConditional Random Fields : Installing CRF++ on Ubuntu\n\n\nConditional Random Fields Training and Testing using CRF++", 
            "title": "CRF in NER"
        }, 
        {
            "location": "/ner_crf/#conditional-random-fields-in-name-entity-recognition", 
            "text": "In this tutorial, I will write about how to using CRF++ to train your data for name entity recognition task.  Environment:   Ubuntu 14.04", 
            "title": "Conditional Random Fields in Name Entity Recognition"
        }, 
        {
            "location": "/ner_crf/#install-crf", 
            "text": "Download CRF++-0.58.tar.gz    Extact CRF++-0.58.tar.gz file    Navigate to the location of extracted folder through    Install CRF++ from source    ./configure\nmake\nsudo make install\nldconfig  Congratulations! CRF++ is install  crf_learn", 
            "title": "Install CRF++"
        }, 
        {
            "location": "/ner_crf/#training-crf", 
            "text": "To train a CRF using CRF++, you need 2 things:   A template file: where you define features to be considered for training  A training data file: where you have data in CoNLL format   crf_learn -t template_file train_data_file model\n\ncrf_learn -t template train.txt model  A binary of model is produce.  To test this model, on a testing data  crf_test -m model testfile   output.txt\n\ncrf_test -m model test.txt   output.txt", 
            "title": "Training CRF"
        }, 
        {
            "location": "/ner_crf/#references", 
            "text": "Conditional Random Fields : Installing CRF++ on Ubuntu  Conditional Random Fields Training and Testing using CRF++", 
            "title": "References"
        }, 
        {
            "location": "/entity_linking/", 
            "text": "Entity Linking\n\n\n\n\nIn natural language processing, \nentity linking\n, \nnamed entity linking (NEL)\n, \nnamed entity disambiguation (NED)\n, \nnamed entity recognition and disambiguation (NERD)\n or \nnamed entity normalization (NEN)\n is the task of determining the identity of entities mentioned in text. More precise, it is the task of linking entity mentions to entries in a knowledge base (e.g., DBpedia, Wikipedia)\n\n\nEntity linking requires a knowledge base containing the entities to which entity mentions can be linked. A popular choice for entity linking on open domain text are knowledge-bases based on Wikipedia, in which each page is regarded as a named entity. NED using Wikipedia entities has been also called wikification (see Wikify! an early entity linking system] ). A knowledge base may also be induced automatically from training text or manually built.\n\n\nNED is different from named entity recognition (NER) in that NER identifies the occurrence or mention of a named entity in text but it does not identify which specific entity it is\n\n\nExamples\n\n\nExample 1:\n\n\nFor example, given the sentence \"Paris is the capital of France\", the idea is to determine that \"Paris\" refers to the city of Paris and not to Paris Hilton or any other entity that could be referred as \"Paris\".\n\n\n\n\nExample 2:\n\n\nGive the sentence \"In Second Debate, Donald Trump and HIllary Clinton Spar in Bitter, Personal Terms\", the idea is to determine that \"Donald Trump\" refer to an American politician, and \"Hillary Clinton\" refer to 67th United States Secretary of State from 2009 to 2013.\n\n\n\n\nArchitecture\n\n\n\n\n\n\nMention detection\n: Identification of text snippets that can potentially be linked to entities\n\n\nCandidate selection\n: Generating a set of candidate entities for each mention\n\n\nDisambiguation\n: Selecting a single entity (or none) for each mention, based on the context\n\n\n\n\nMention detection\n\n\n\n\nGoal: Detect all \"linkable\" phrases\n\n\nChallenges:\n\n\n\n\nRecall oriented: Do not miss any entity that should be link\n\n\nFind entity name variants (e.g. \"jlo\" is name variant of [Jennifer Lopez])\n\n\nFilter out inappropriate ones (e.g. \"new york\" matches \n2k different entities)\n\n\n\n\nCommon Approach\n\n\n\n\n\n\nBuild a dictionary of entity surface forms\n\n\n\n\n\n\nentities with all names variants\n\n\n\n\n\n\nCheck all document n-grams against the dictionary\n\n\n\n\n\n\nthe value of n is set typically between 6 and 8\n\n\n\n\n\n\nFilter out undesired entities\n\n\n\n\n\n\nCan be done here or later in the pipeline\n\n\n\n\n\n\nExamples\n\n\n\n\nCandidate Selection\n\n\n\n\nGoal: Narrow down the space of disambiguation possibilities\n\n\nBalances between precision and recall (effectiveness vs. efficiency)\n\n\nOften approached as ranking problem: keeping only candidates above a score/rank threshold for downstream processing.\n\n\nCommonness\n\n\nPerform the ranking of candidate entities based on their overall popularity, i.e., \"most command sense\"\n\n\n\n\nExamples\n\n\n\n\nCommonness can be pre-computed and stored in the entity surface form dictionary. Follows a power law with a long tail of extremely unlikely senses; entities at the tail end of distribution can be safely discarded (e.g., 0.001 is sensible threshold)\n\n\n\n\nDisambiguation\n\n\n\n\nBaseline approach: most common sense\n\n\nConsider additional types of evidence: \nprior importance\n of entities and mentions, \ncontextual similarity\n between the text surrounding the mention and the candidate entity, \ncoherence\n among all entity linking decisions in the document.\n\n\nCombine these signals: using supervised learning or graph-based approaches\n\n\nOptionally perform pruning: reject low confidence or semantically meaning less annotations.\n\n\nReferences\n\n\n\n\n\"Entity Linking\". \nwikipedia\n\n\n\"Entity Linking\". \nKrisztian Balog, University of Stavanger, 10th Russian Summer School in Information Retrieval\n. 2016\n\n\n\"An End-to-End Entity Linking Approach for Tweets\". \nIkuya Yamada, Hideaki Takeda, Yoshiyasu Takefuji\n. 2015", 
            "title": "Entity Linking"
        }, 
        {
            "location": "/entity_linking/#entity-linking", 
            "text": "In natural language processing,  entity linking ,  named entity linking (NEL) ,  named entity disambiguation (NED) ,  named entity recognition and disambiguation (NERD)  or  named entity normalization (NEN)  is the task of determining the identity of entities mentioned in text. More precise, it is the task of linking entity mentions to entries in a knowledge base (e.g., DBpedia, Wikipedia)  Entity linking requires a knowledge base containing the entities to which entity mentions can be linked. A popular choice for entity linking on open domain text are knowledge-bases based on Wikipedia, in which each page is regarded as a named entity. NED using Wikipedia entities has been also called wikification (see Wikify! an early entity linking system] ). A knowledge base may also be induced automatically from training text or manually built.  NED is different from named entity recognition (NER) in that NER identifies the occurrence or mention of a named entity in text but it does not identify which specific entity it is", 
            "title": "Entity Linking"
        }, 
        {
            "location": "/entity_linking/#examples", 
            "text": "Example 1:  For example, given the sentence \"Paris is the capital of France\", the idea is to determine that \"Paris\" refers to the city of Paris and not to Paris Hilton or any other entity that could be referred as \"Paris\".   Example 2:  Give the sentence \"In Second Debate, Donald Trump and HIllary Clinton Spar in Bitter, Personal Terms\", the idea is to determine that \"Donald Trump\" refer to an American politician, and \"Hillary Clinton\" refer to 67th United States Secretary of State from 2009 to 2013.", 
            "title": "Examples"
        }, 
        {
            "location": "/entity_linking/#architecture", 
            "text": "Mention detection : Identification of text snippets that can potentially be linked to entities  Candidate selection : Generating a set of candidate entities for each mention  Disambiguation : Selecting a single entity (or none) for each mention, based on the context", 
            "title": "Architecture"
        }, 
        {
            "location": "/entity_linking/#mention-detection", 
            "text": "Goal: Detect all \"linkable\" phrases  Challenges:   Recall oriented: Do not miss any entity that should be link  Find entity name variants (e.g. \"jlo\" is name variant of [Jennifer Lopez])  Filter out inappropriate ones (e.g. \"new york\" matches  2k different entities)", 
            "title": "Mention detection"
        }, 
        {
            "location": "/entity_linking/#common-approach", 
            "text": "Build a dictionary of entity surface forms    entities with all names variants    Check all document n-grams against the dictionary    the value of n is set typically between 6 and 8    Filter out undesired entities    Can be done here or later in the pipeline    Examples", 
            "title": "Common Approach"
        }, 
        {
            "location": "/entity_linking/#candidate-selection", 
            "text": "Goal: Narrow down the space of disambiguation possibilities  Balances between precision and recall (effectiveness vs. efficiency)  Often approached as ranking problem: keeping only candidates above a score/rank threshold for downstream processing.", 
            "title": "Candidate Selection"
        }, 
        {
            "location": "/entity_linking/#commonness", 
            "text": "Perform the ranking of candidate entities based on their overall popularity, i.e., \"most command sense\"   Examples   Commonness can be pre-computed and stored in the entity surface form dictionary. Follows a power law with a long tail of extremely unlikely senses; entities at the tail end of distribution can be safely discarded (e.g., 0.001 is sensible threshold)", 
            "title": "Commonness"
        }, 
        {
            "location": "/entity_linking/#disambiguation", 
            "text": "Baseline approach: most common sense  Consider additional types of evidence:  prior importance  of entities and mentions,  contextual similarity  between the text surrounding the mention and the candidate entity,  coherence  among all entity linking decisions in the document.  Combine these signals: using supervised learning or graph-based approaches  Optionally perform pruning: reject low confidence or semantically meaning less annotations.", 
            "title": "Disambiguation"
        }, 
        {
            "location": "/entity_linking/#references", 
            "text": "\"Entity Linking\".  wikipedia  \"Entity Linking\".  Krisztian Balog, University of Stavanger, 10th Russian Summer School in Information Retrieval . 2016  \"An End-to-End Entity Linking Approach for Tweets\".  Ikuya Yamada, Hideaki Takeda, Yoshiyasu Takefuji . 2015", 
            "title": "References"
        }, 
        {
            "location": "/application/", 
            "text": "NLP Applications\n\n\nInformation Retrieval (IR)\n\n\nInformation retrieval (IR) is the activity of obtaining information resources relevant to an information need from a collection of information resources. Searches can be based on metadata or on full-text (or other content-based) indexing.\n\n\nInformation Extraction (IE)\n\n\nInformation extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP).\n\n\nMachine Translation\n\n\nMachine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation) is a sub-field of computational linguistics that investigates the use of software to translate text or speech from one language to another.\n\n\nQuestion Answering (QA)\n\n\nQuestion answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.", 
            "title": "Applications"
        }, 
        {
            "location": "/application/#nlp-applications", 
            "text": "", 
            "title": "NLP Applications"
        }, 
        {
            "location": "/application/#information-retrieval-ir", 
            "text": "Information retrieval (IR) is the activity of obtaining information resources relevant to an information need from a collection of information resources. Searches can be based on metadata or on full-text (or other content-based) indexing.", 
            "title": "Information Retrieval (IR)"
        }, 
        {
            "location": "/application/#information-extraction-ie", 
            "text": "Information extraction (IE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most of the cases this activity concerns processing human language texts by means of natural language processing (NLP).", 
            "title": "Information Extraction (IE)"
        }, 
        {
            "location": "/application/#machine-translation", 
            "text": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation) is a sub-field of computational linguistics that investigates the use of software to translate text or speech from one language to another.", 
            "title": "Machine Translation"
        }, 
        {
            "location": "/application/#question-answering-qa", 
            "text": "Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.", 
            "title": "Question Answering (QA)"
        }, 
        {
            "location": "/vietnlp/", 
            "text": "Vietnamese NLP\n\n\n\n\n\n\n\n\nTasks\n\n\nDictionaries\n\n\n\n\nThe Free Vietnamese Dictionary Project. H\u1ed3 Ng\u1ecdc \u0110\u1ee9c. 2004\n, 30000 words\n\n\n\n\nWordnet\n\n\n\n\nviet wordnet. 2015\n, 67344 words\n\n\n\n\nCorpus\n\n\nviwikipedia dump. 2016\n, ~500 MB\n\n\nVNESEcorpus. 2012\n, 650.000 sentences, 10.000 articles from vietnamnet.vn, dantri.com.vn, nhanhdan.com.vn. Size: 64.59 Mb\n\n\nVNTQcorpus(small). 2012\n, 300.000 sentences, 1.000 articles from vnthuquan.net\nSize: ~35 Mb\n\n\nVNTQcorpus(big). 2012\n, 1.750.000 sentences, 13.000 articles from vnthuquan.net, Size: ~240 Mb\n\n\nWord Segmentation\n\n\nsources \n1\n\n\nData\n\n\n\n\nVLSP 2013: Word Segmentation Task, 77000 sentences\n\n\nData from JVnSegmenter\n, 7800 sentences\n\n\n\n\nBenchmark\n\n\nUnit: F1 (%)\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nPOS Tagging\n\n\nsources \n1\n\n\nData\n\n\n\n\n[N09] VLSP 2013: POS Tagging Task, 270000 sentences\n\n\n\n\nBenchmark\n\n\nUnit: F1 (%)\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nDependency Parsing\n\n\nsources \n1\n\n\nBenchmark\n\n\nUnit: %\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nChunking\n\n\nsources \n1\n\n\nData\n\n\n\n\nTraining data from vTools\n\n\n\n\nBenchmark\n\n\nUnit: %\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nNamed Entity Recognition\n\n\nsources \n1\n\n\nData\n\n\n\n\nVLSP 2016: NER Task, 313 documents, 19160 sentences\n\n\n\n\nBenchmark\n\n\nUnit: %\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nCoreference Resolution\n\n\nsources \n1\n\n\nBenchmark\n\n\nUnit: %\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nSpelling Correction\n\n\nBenchmark\n\n\n\n\n\n\n\n\nSentiment Analysis\n\n\nData\n\n\n\n\nVietSentiWordNet\n, 1000 synsets\n\n\nVLSP 2016: OM Task, 3600 sentences\n\n\n\n\nBenchmark\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nAutomatic Summarization\n\n\nData\n\n\n\n\n200 C\u1ee5m v\u0103n b\u1ea3n ti\u1ebfng Vi\u1ec7t d\u00f9ng cho t\u00f3m t\u1eaft \u0111a v\u0103n b\u1ea3n. 2012\n\n\n\n\nOptical Character Recognition\n\n\nData\n\n\n\n\nD\u1eef li\u1ec7u cho b\u00e0i to\u00e1n nh\u1eadn d\u1ea1ng ch\u1eef vi\u1ebft tay ti\u1ebfng Vi\u1ec7t. 2011\n\n\n\n\nMachine Translation\n\n\nBenchmark\n\n\n\n\n\n\n\n\nGroups and People\n\n\nGroups\n\n\n\n\nmica (2002-now)\n\n\nvlsp (2006-now)\n\n\nDSKTLab (2010-now)\n\n\nKDE lab, (2014-now)\n\n\n\n\nPeople\n\n\n\n\nHa Quang Thuy\n\n\nHo Tu Bao\n\n\nLe Hong Phuong\n\n\nLe Thanh Huong\n\n\nLuong Chi Mai\n\n\nNguyen Cam Tu\n\n\nNguyen Cam Tu\n\n\nNguyen Dat Quoc\n\n\nNguyen Kiem Hieu\n\n\nNguyen Thi Minh Huyen\n\n\nPhan Xuan Hieu\n\n\nThan Quang Khoat\n\n\nTran Mai Vu\n\n\n\n\nApplications\n\n\nVietnam Artificial Intelligent Sytems (VAIS)\n\n\nTime: 2016\n\n\n\n\nVAIS-TTS\n: the speech synthesis service. Our system provides both northern and southern region voices with high quality, high availability, and easy-to-access service for everyone!.\n\n\nVAIS-MT\n: : the machine translation service. Our system provides natural machine translation results between Vietnamese-English languages by utilizing the state-of-the-art neural network technique.\n\n\n\n\nVAV - Tr\u1ee3 l\u00fd \u1ea3o cho ng\u01b0\u1eddi Vi\u1ec7t\n\n\nTime: Nov 2015 - now\n\n\nMDN-Team, Khoa CNTT, Tr\u01b0\u1eddng \u0110H C\u00f4ng ngh\u1ec7, \u0110HQG HN Tools\n\n\nB\u1ea1n \u0111ang ngh\u0129 \u0111\u1ebfn m\u1ed9t \u1ee9ng d\u1ee5ng th\u00f4ng minh tr\u00ean di \u0111\u1ed9ng cho ph\u00e9p b\u1ea1n t\u01b0\u01a1ng t\u00e1c b\u1eb1ng gi\u1ecdng n\u00f3i \u0111\u1ec3 h\u1eb9n chu\u00f4ng b\u00e1o th\u1ee9c, \u0111\u1eb7t l\u1ecbch cho m\u1ed9t cu\u1ed9c h\u1ecdp, b\u1eadt \u0111\u1ecbnh v\u1ecb, g\u1ecdi \u0111i\u1ec7n cho ai \u0111\u00f3, truy c\u1eadp m\u1ed9t trang web b\u1ea5t k\u1ef3, t\u00ecm \u0111\u01b0\u1eddng tr\u00ean b\u1ea3n \u0111\u1ed3, \u0111\u1ecbnh v\u1ecb c\u00e2y ATM c\u1ee7a m\u1ed9t ng\u00e2n h\u00e0ng n\u00e0o \u0111\u00f3 g\u1ea7n v\u1edbi b\u1ea1n, hay th\u01b0\u1edfng th\u1ee9c m\u1ed9t b\u1ea3n nh\u1ea1c m\u00ecnh y\u00eau th\u00edch \u2026 \u1ee8ng d\u1ee5ng Tr\u1ee3 l\u00fd \u1ea3o VAV ch\u00ednh l\u00e0 c\u00e2u tr\u1ea3 l\u1eddi cho b\u1ea1n. \u0110\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u00e0 ph\u00e1t tri\u1ec3n d\u1ef1a tr\u00ean c\u00e1c k\u1ef9 thu\u1eadt tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (h\u1ecdc m\u00e1y, ph\u00e2n t\u00edch v\u00e0 hi\u1ec3u ng\u00f4n ng\u1eef t\u1ef1 nhi\u00ean), VAV c\u00f3 th\u1ec3 hi\u1ec3u \u0111\u01b0\u1ee3c \u00fd \u0111\u1ecbnh c\u1ee7a b\u1ea1n d\u00f9 b\u1ea1n di\u1ec5n \u0111\u1ea1t c\u00e2u l\u1ec7nh c\u1ee7a m\u00ecnh theo nhi\u1ec1u c\u00e1ch kh\u00e1c nhau m\u00e0 kh\u00f4ng c\u1ea7n tu\u00e2n theo b\u1ea5t k\u1ef3 khu\u00f4n m\u1eabu n\u00e0o cho tr\u01b0\u1edbc. Nh\u1eefng g\u00ec VAV h\u01b0\u1edbng t\u1edbi l\u00e0 tr\u1edf th\u00e0nh m\u1ed9t tr\u1ee3 l\u00fd \u1ea3o th\u00f4ng minh gi\u00fap b\u1ea1n th\u1ef1c hi\u1ec7n nh\u1eefng \u0111i\u1ec1u m\u00ecnh mu\u1ed1n v\u00e0 l\u00e0 m\u1ed9t ng\u01b0\u1eddi \u0111\u1ed3ng h\u00e0nh th\u00e2n thi\u1ec7n, d\u00ed d\u1ecfm b\u00ean b\u1ea1n.\n\n\nReferences\n\n\n\n\n\n\n\n\n\n\n2016, Big Challenges for Data Scientists at VCCORP", 
            "title": "Vietnamese"
        }, 
        {
            "location": "/vietnlp/#vietnamese-nlp", 
            "text": "", 
            "title": "Vietnamese NLP"
        }, 
        {
            "location": "/vietnlp/#tasks", 
            "text": "", 
            "title": "Tasks"
        }, 
        {
            "location": "/vietnlp/#dictionaries", 
            "text": "The Free Vietnamese Dictionary Project. H\u1ed3 Ng\u1ecdc \u0110\u1ee9c. 2004 , 30000 words", 
            "title": "Dictionaries"
        }, 
        {
            "location": "/vietnlp/#wordnet", 
            "text": "viet wordnet. 2015 , 67344 words", 
            "title": "Wordnet"
        }, 
        {
            "location": "/vietnlp/#corpus", 
            "text": "viwikipedia dump. 2016 , ~500 MB  VNESEcorpus. 2012 , 650.000 sentences, 10.000 articles from vietnamnet.vn, dantri.com.vn, nhanhdan.com.vn. Size: 64.59 Mb  VNTQcorpus(small). 2012 , 300.000 sentences, 1.000 articles from vnthuquan.net\nSize: ~35 Mb  VNTQcorpus(big). 2012 , 1.750.000 sentences, 13.000 articles from vnthuquan.net, Size: ~240 Mb", 
            "title": "Corpus"
        }, 
        {
            "location": "/vietnlp/#word-segmentation", 
            "text": "sources  1", 
            "title": "Word Segmentation"
        }, 
        {
            "location": "/vietnlp/#data", 
            "text": "VLSP 2013: Word Segmentation Task, 77000 sentences  Data from JVnSegmenter , 7800 sentences", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#benchmark", 
            "text": "Unit: F1 (%)", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#pos-tagging", 
            "text": "sources  1", 
            "title": "POS Tagging"
        }, 
        {
            "location": "/vietnlp/#data_1", 
            "text": "[N09] VLSP 2013: POS Tagging Task, 270000 sentences", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#benchmark_1", 
            "text": "Unit: F1 (%)", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_1", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#dependency-parsing", 
            "text": "sources  1", 
            "title": "Dependency Parsing"
        }, 
        {
            "location": "/vietnlp/#benchmark_2", 
            "text": "Unit: %", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_2", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#chunking", 
            "text": "sources  1", 
            "title": "Chunking"
        }, 
        {
            "location": "/vietnlp/#data_2", 
            "text": "Training data from vTools", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#benchmark_3", 
            "text": "Unit: %", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_3", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#named-entity-recognition", 
            "text": "sources  1", 
            "title": "Named Entity Recognition"
        }, 
        {
            "location": "/vietnlp/#data_3", 
            "text": "VLSP 2016: NER Task, 313 documents, 19160 sentences", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#benchmark_4", 
            "text": "Unit: %", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_4", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#coreference-resolution", 
            "text": "sources  1", 
            "title": "Coreference Resolution"
        }, 
        {
            "location": "/vietnlp/#benchmark_5", 
            "text": "Unit: %", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_5", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#spelling-correction", 
            "text": "", 
            "title": "Spelling Correction"
        }, 
        {
            "location": "/vietnlp/#benchmark_6", 
            "text": "", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#sentiment-analysis", 
            "text": "", 
            "title": "Sentiment Analysis"
        }, 
        {
            "location": "/vietnlp/#data_4", 
            "text": "VietSentiWordNet , 1000 synsets  VLSP 2016: OM Task, 3600 sentences", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#benchmark_7", 
            "text": "", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#related-readings_6", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/vietnlp/#automatic-summarization", 
            "text": "", 
            "title": "Automatic Summarization"
        }, 
        {
            "location": "/vietnlp/#data_5", 
            "text": "200 C\u1ee5m v\u0103n b\u1ea3n ti\u1ebfng Vi\u1ec7t d\u00f9ng cho t\u00f3m t\u1eaft \u0111a v\u0103n b\u1ea3n. 2012", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#optical-character-recognition", 
            "text": "", 
            "title": "Optical Character Recognition"
        }, 
        {
            "location": "/vietnlp/#data_6", 
            "text": "D\u1eef li\u1ec7u cho b\u00e0i to\u00e1n nh\u1eadn d\u1ea1ng ch\u1eef vi\u1ebft tay ti\u1ebfng Vi\u1ec7t. 2011", 
            "title": "Data"
        }, 
        {
            "location": "/vietnlp/#machine-translation", 
            "text": "", 
            "title": "Machine Translation"
        }, 
        {
            "location": "/vietnlp/#benchmark_8", 
            "text": "", 
            "title": "Benchmark"
        }, 
        {
            "location": "/vietnlp/#groups-and-people", 
            "text": "Groups   mica (2002-now)  vlsp (2006-now)  DSKTLab (2010-now)  KDE lab, (2014-now)   People   Ha Quang Thuy  Ho Tu Bao  Le Hong Phuong  Le Thanh Huong  Luong Chi Mai  Nguyen Cam Tu  Nguyen Cam Tu  Nguyen Dat Quoc  Nguyen Kiem Hieu  Nguyen Thi Minh Huyen  Phan Xuan Hieu  Than Quang Khoat  Tran Mai Vu", 
            "title": "Groups and People"
        }, 
        {
            "location": "/vietnlp/#applications", 
            "text": "", 
            "title": "Applications"
        }, 
        {
            "location": "/vietnlp/#vietnam-artificial-intelligent-sytems-vais", 
            "text": "Time: 2016   VAIS-TTS : the speech synthesis service. Our system provides both northern and southern region voices with high quality, high availability, and easy-to-access service for everyone!.  VAIS-MT : : the machine translation service. Our system provides natural machine translation results between Vietnamese-English languages by utilizing the state-of-the-art neural network technique.", 
            "title": "Vietnam Artificial Intelligent Sytems (VAIS)"
        }, 
        {
            "location": "/vietnlp/#vav-tro-ly-ao-cho-nguoi-viet", 
            "text": "Time: Nov 2015 - now  MDN-Team, Khoa CNTT, Tr\u01b0\u1eddng \u0110H C\u00f4ng ngh\u1ec7, \u0110HQG HN Tools  B\u1ea1n \u0111ang ngh\u0129 \u0111\u1ebfn m\u1ed9t \u1ee9ng d\u1ee5ng th\u00f4ng minh tr\u00ean di \u0111\u1ed9ng cho ph\u00e9p b\u1ea1n t\u01b0\u01a1ng t\u00e1c b\u1eb1ng gi\u1ecdng n\u00f3i \u0111\u1ec3 h\u1eb9n chu\u00f4ng b\u00e1o th\u1ee9c, \u0111\u1eb7t l\u1ecbch cho m\u1ed9t cu\u1ed9c h\u1ecdp, b\u1eadt \u0111\u1ecbnh v\u1ecb, g\u1ecdi \u0111i\u1ec7n cho ai \u0111\u00f3, truy c\u1eadp m\u1ed9t trang web b\u1ea5t k\u1ef3, t\u00ecm \u0111\u01b0\u1eddng tr\u00ean b\u1ea3n \u0111\u1ed3, \u0111\u1ecbnh v\u1ecb c\u00e2y ATM c\u1ee7a m\u1ed9t ng\u00e2n h\u00e0ng n\u00e0o \u0111\u00f3 g\u1ea7n v\u1edbi b\u1ea1n, hay th\u01b0\u1edfng th\u1ee9c m\u1ed9t b\u1ea3n nh\u1ea1c m\u00ecnh y\u00eau th\u00edch \u2026 \u1ee8ng d\u1ee5ng Tr\u1ee3 l\u00fd \u1ea3o VAV ch\u00ednh l\u00e0 c\u00e2u tr\u1ea3 l\u1eddi cho b\u1ea1n. \u0110\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u00e0 ph\u00e1t tri\u1ec3n d\u1ef1a tr\u00ean c\u00e1c k\u1ef9 thu\u1eadt tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (h\u1ecdc m\u00e1y, ph\u00e2n t\u00edch v\u00e0 hi\u1ec3u ng\u00f4n ng\u1eef t\u1ef1 nhi\u00ean), VAV c\u00f3 th\u1ec3 hi\u1ec3u \u0111\u01b0\u1ee3c \u00fd \u0111\u1ecbnh c\u1ee7a b\u1ea1n d\u00f9 b\u1ea1n di\u1ec5n \u0111\u1ea1t c\u00e2u l\u1ec7nh c\u1ee7a m\u00ecnh theo nhi\u1ec1u c\u00e1ch kh\u00e1c nhau m\u00e0 kh\u00f4ng c\u1ea7n tu\u00e2n theo b\u1ea5t k\u1ef3 khu\u00f4n m\u1eabu n\u00e0o cho tr\u01b0\u1edbc. Nh\u1eefng g\u00ec VAV h\u01b0\u1edbng t\u1edbi l\u00e0 tr\u1edf th\u00e0nh m\u1ed9t tr\u1ee3 l\u00fd \u1ea3o th\u00f4ng minh gi\u00fap b\u1ea1n th\u1ef1c hi\u1ec7n nh\u1eefng \u0111i\u1ec1u m\u00ecnh mu\u1ed1n v\u00e0 l\u00e0 m\u1ed9t ng\u01b0\u1eddi \u0111\u1ed3ng h\u00e0nh th\u00e2n thi\u1ec7n, d\u00ed d\u1ecfm b\u00ean b\u1ea1n.", 
            "title": "VAV - Tr\u1ee3 l\u00fd \u1ea3o cho ng\u01b0\u1eddi Vi\u1ec7t"
        }, 
        {
            "location": "/vietnlp/#references", 
            "text": "2016, Big Challenges for Data Scientists at VCCORP", 
            "title": "References"
        }, 
        {
            "location": "/englishnlp/", 
            "text": "English NLP\n\n\nTasks\n\n\nChunking\n\n\nData\n\n\n\n\nCoNLL-2000 Shared Task: Chunking\n, 259104 tokens\n\n\n\n\nBenchmark\n\n\nCoNLL-2000\n (\nscore: F1(%)\n)\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nNamed Entity Recognition\n\n\nData\n\n\n\n\nCoNLL-2003 Shared Task:Language-Independent Named Entity Recognition\n\n\nMUC-7\n\n\n\n\nBenchmark\n\n\nCoNLL-2003\n (\nscore: F1\n)\n\n\n\n\n\n\n\n\nMUC-7\n (\nscore: F1\n)\n\n\n\n\n\n\n\n\nRelated Readings\n\n\n\n\n\n\n\n\nSimilarity\n\n\nData\n\n\n\n\nSemEval-2012 Task 2\n, Measuring Degrees of Relational Similarity, graded relational similarity ratings across 79 relation categories\n\n\nESL Synonym Questions\n, 50 multiple-choice synonym questions; 4 choices per question, each question includes a sentence, providing context for the question, introduced in Turney (2001) as a way of evaluating algorithms for measuring degree of similarity between words\n\n\nMC-28 Test Collection\n, state of the art in Miller \n Charles 28 (MC-28) dataset [Resnik, 1995], 28 word pairs of the original Miller \n Charles 30 (MC-30) dataset [Miller and Charles, 1991], which is a subset of the Rubenstein \n Goodenough (RG-65) dataset; two word pairs have generally been omitted for semantic similarity evaluation, as words in these word pairs have not been included in previous versions of WordNet\n\n\n\n\nBenchmark\n\n\nSemEval-2012 Task 2\n (\nscore: MaxDiff, Spearman\n)\n\n\n\n\n\n\n\n\nESL Synonym Questions\n (\nscore: Correct\n)\n\n\n\n\n\n\n\n\nMC-28 Test Collection\n (\nscore: Spearman\n)\n\n\n\n\n\n\n\n\nParaphase Identification\n\n\nData\n\n\n\n\nMicrosoft Research Paraphrase Corpus\n, given a pair of sentences, classify them as paraphrases or not paraphrases, train: 4,076 sentence pairs (2,753 positive: 67.5%)\ntest: 1,725 sentence pairs (1,147 positive: 66.5%)\n\n\n\n\nBenchmark\n\n\nMicrosoft Research Paraphrase Corpus\n (\nscore: Accuracy, F\n)\n\n\n\n\n\n\n\n\nQuestion Answering\n\n\nData\n\n\n\n\nQA Answer Sentence Selection Dataset\n: labeled sentences using TREC QA track data, provided by Mengqiu Wang and first used in Wang et al. (2007)\n\n\n\n\nBenchmark\n\n\nRaw Version of TREC QA\n (\nscore: MAP, MRR\n)\n\n\n\n\n\n\n\n\nClean Version of TREC QA\n (\nscore: MAP, MRR\n)", 
            "title": "English"
        }, 
        {
            "location": "/englishnlp/#english-nlp", 
            "text": "", 
            "title": "English NLP"
        }, 
        {
            "location": "/englishnlp/#tasks", 
            "text": "", 
            "title": "Tasks"
        }, 
        {
            "location": "/englishnlp/#chunking", 
            "text": "", 
            "title": "Chunking"
        }, 
        {
            "location": "/englishnlp/#data", 
            "text": "CoNLL-2000 Shared Task: Chunking , 259104 tokens", 
            "title": "Data"
        }, 
        {
            "location": "/englishnlp/#benchmark", 
            "text": "CoNLL-2000  ( score: F1(%) )", 
            "title": "Benchmark"
        }, 
        {
            "location": "/englishnlp/#related-readings", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/englishnlp/#named-entity-recognition", 
            "text": "", 
            "title": "Named Entity Recognition"
        }, 
        {
            "location": "/englishnlp/#data_1", 
            "text": "CoNLL-2003 Shared Task:Language-Independent Named Entity Recognition  MUC-7", 
            "title": "Data"
        }, 
        {
            "location": "/englishnlp/#benchmark_1", 
            "text": "CoNLL-2003  ( score: F1 )    MUC-7  ( score: F1 )", 
            "title": "Benchmark"
        }, 
        {
            "location": "/englishnlp/#related-readings_1", 
            "text": "", 
            "title": "Related Readings"
        }, 
        {
            "location": "/englishnlp/#similarity", 
            "text": "", 
            "title": "Similarity"
        }, 
        {
            "location": "/englishnlp/#data_2", 
            "text": "SemEval-2012 Task 2 , Measuring Degrees of Relational Similarity, graded relational similarity ratings across 79 relation categories  ESL Synonym Questions , 50 multiple-choice synonym questions; 4 choices per question, each question includes a sentence, providing context for the question, introduced in Turney (2001) as a way of evaluating algorithms for measuring degree of similarity between words  MC-28 Test Collection , state of the art in Miller   Charles 28 (MC-28) dataset [Resnik, 1995], 28 word pairs of the original Miller   Charles 30 (MC-30) dataset [Miller and Charles, 1991], which is a subset of the Rubenstein   Goodenough (RG-65) dataset; two word pairs have generally been omitted for semantic similarity evaluation, as words in these word pairs have not been included in previous versions of WordNet", 
            "title": "Data"
        }, 
        {
            "location": "/englishnlp/#benchmark_2", 
            "text": "SemEval-2012 Task 2  ( score: MaxDiff, Spearman )    ESL Synonym Questions  ( score: Correct )    MC-28 Test Collection  ( score: Spearman )", 
            "title": "Benchmark"
        }, 
        {
            "location": "/englishnlp/#paraphase-identification", 
            "text": "", 
            "title": "Paraphase Identification"
        }, 
        {
            "location": "/englishnlp/#data_3", 
            "text": "Microsoft Research Paraphrase Corpus , given a pair of sentences, classify them as paraphrases or not paraphrases, train: 4,076 sentence pairs (2,753 positive: 67.5%)\ntest: 1,725 sentence pairs (1,147 positive: 66.5%)", 
            "title": "Data"
        }, 
        {
            "location": "/englishnlp/#benchmark_3", 
            "text": "Microsoft Research Paraphrase Corpus  ( score: Accuracy, F )", 
            "title": "Benchmark"
        }, 
        {
            "location": "/englishnlp/#question-answering", 
            "text": "", 
            "title": "Question Answering"
        }, 
        {
            "location": "/englishnlp/#data_4", 
            "text": "QA Answer Sentence Selection Dataset : labeled sentences using TREC QA track data, provided by Mengqiu Wang and first used in Wang et al. (2007)", 
            "title": "Data"
        }, 
        {
            "location": "/englishnlp/#benchmark_4", 
            "text": "Raw Version of TREC QA  ( score: MAP, MRR )    Clean Version of TREC QA  ( score: MAP, MRR )", 
            "title": "Benchmark"
        }, 
        {
            "location": "/feed/", 
            "text": "Latest News", 
            "title": "<span class='fa fa-rss'></span> News"
        }, 
        {
            "location": "/feed/#latest-news", 
            "text": "", 
            "title": "Latest News"
        }
    ]
}